{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29b9fb3e",
   "metadata": {},
   "source": [
    "# EYE DETECTION PROJECT USING NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dd2862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "from imutils import face_utils\n",
    "import dlib\n",
    "from scipy.spatial import distance\n",
    "from pygame import mixer\n",
    "from colorama import init, Fore\n",
    "\n",
    "# Initialize colorama\n",
    "init(autoreset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6f3b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixer.init()\n",
    "mixer.music.load('music.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cc2b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "import cv2\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "from pygame import mixer\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    A = distance.euclidean(eye[1], eye[5])\n",
    "    B = distance.euclidean(eye[2], eye[4])\n",
    "    C = distance.euclidean(eye[0], eye[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear # EAR = EAR ASPECT RATIO\n",
    "\n",
    "thresh = 0.25\n",
    "flag = 0\n",
    "frame_check = 20\n",
    "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_68_IDXS['left_eye'] #LEFT SIDE EYE CHECK\n",
    "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_68_IDXS['right_eye'] #RIGHT SIDE EYW CHECK\n",
    "\n",
    "detect = dlib.get_frontal_face_detector()\n",
    "predict = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "cap = cv2.VideoCapture(0) #(0) IS FOR SINGLE DEFAULT CAMERA WHERE AS WE CAN PUT 1,2,3, & SO ON TO CONNECT MULTIPLE CAM.\n",
    "\n",
    "mixer.init()\n",
    "mixer.music.load('music.wav')  # Provide the correct path to your alert sound\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    subjects = detect(gray, 0)\n",
    "\n",
    "    for subject in subjects:\n",
    "        shape = predict(gray, subject)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        leftEye = shape[lStart:lEnd]\n",
    "        rightEye = shape[rStart:rEnd]\n",
    "        leftEar = eye_aspect_ratio(leftEye)\n",
    "        rightEar = eye_aspect_ratio(rightEye)\n",
    "        ear = (leftEar + rightEar) / 2.0 # FORMULA FOR EAR\n",
    "\n",
    "        leftEyeHull = cv2.convexHull(leftEye)\n",
    "        rightEyeHull = cv2.convexHull(rightEye)\n",
    "\n",
    "        cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1) # COLOR EFFECT FOR LEFT EYE OUTPUT\n",
    "        cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1) # COLOR EFFECT FOR RIGHT EYE OUTPUT\n",
    "\n",
    "        if ear < thresh:\n",
    "            flag += 1\n",
    "            print(flag)\n",
    "            if flag >= frame_check:\n",
    "                cv2.putText(frame, '*******************Alert*************', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7,\n",
    "                            (0, 0, 255), 2)\n",
    "                cv2.putText(frame, '*******************Alert*************', (10, 325), cv2.FONT_HERSHEY_SIMPLEX, 0.7,\n",
    "                            (0, 0, 255), 2)\n",
    "                mixer.music.play()\n",
    "        else:\n",
    "            flag = 0\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bb8b56",
   "metadata": {},
   "source": [
    "# Title: Real-time Eye Movement Detection System for Safe Driving and Productive Work Environments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ea73c8",
   "metadata": {},
   "source": [
    "## *****************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15207f87",
   "metadata": {},
   "source": [
    "## Introduction:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6028fa9a",
   "metadata": {},
   "source": [
    "In today's fast-paced world, ensuring safety during activities like driving and promoting focus during classes or office work is crucial. This project aims to develop a real-time eye movement detection system to enhance safety and productivity in these scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbb309f",
   "metadata": {},
   "source": [
    "## *****************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30013516",
   "metadata": {},
   "source": [
    "## Objectives:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec00630c",
   "metadata": {},
   "source": [
    "1) To implement a robust eye movement detection algorithm.\n",
    "2) To integrate the system into real-world applications such \n",
    "    as driving, attending classes, and office work.\n",
    "3) To enhance safety by detecting signs of driver drowsiness and \n",
    "    inattentiveness.\n",
    "4) To improve focus and productivity by providing feedback on \n",
    "    attentiveness during classes or office tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4792a9",
   "metadata": {},
   "source": [
    "## *****************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc59f5c3",
   "metadata": {},
   "source": [
    "## Key Features:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2921643d",
   "metadata": {},
   "source": [
    "### 1. Real-time Eye Tracking:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db87a2c6",
   "metadata": {},
   "source": [
    "- Utilize advanced computer vision techniques to track eye movements \n",
    "    in real-time.\n",
    "- Implement algorithms for accurate detection of gaze direction and\n",
    "    blink frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec41a91b",
   "metadata": {},
   "source": [
    "## 2. Application Integration:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a988d0f",
   "metadata": {},
   "source": [
    "- Develop modules tailored for specific scenarios: driving, class \n",
    "    attendance, and office work.\n",
    "- Ensure seamless integration with existing systems or as a \n",
    "    standalone application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463c7358",
   "metadata": {},
   "source": [
    "## 3. Class/Office Attentiveness Monitoring:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fa018a",
   "metadata": {},
   "source": [
    "- Create mechanisms to assess attentiveness during classes or office \n",
    "    tasks.\n",
    "- Provide feedback or notifications to users to maintain focus and \n",
    "    productivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1aa5cc",
   "metadata": {},
   "source": [
    "## *****************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82863a7e",
   "metadata": {},
   "source": [
    "# Technology Stack:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd54e31",
   "metadata": {},
   "source": [
    "## 1. Computer Vision:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d6bb69",
   "metadata": {},
   "source": [
    "- OpenCV for real-time image processing and feature extraction.\n",
    "- Machine learning models for eye movement prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecb1e9b",
   "metadata": {},
   "source": [
    "## 2. User Interface:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a0f6d3",
   "metadata": {},
   "source": [
    "- Design a user-friendly interface for visualizing eye movement data \n",
    "    and receiving alerts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc53b5e",
   "metadata": {},
   "source": [
    "## *****************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6469f0bd",
   "metadata": {},
   "source": [
    "# Expected Outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e59daf",
   "metadata": {},
   "source": [
    "- A reliable and accurate eye movement detection system.\n",
    "- Integration with driving systems, classroom settings, and office \n",
    "    environments.\n",
    "- Improved safety on the road through driver drowsiness detection.\n",
    "- Enhanced productivity by promoting attentiveness during classes \n",
    "    and work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a269867f",
   "metadata": {},
   "source": [
    "## *****************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e19267c",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470ac069",
   "metadata": {},
   "source": [
    "- This project seeks to address safety concerns and boost productivity in various scenarios by implementing a sophisticated real-time eye movement detection system. The integration of this system into educational, and office environments holds the potential to make a significant impact on user safety and focus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec095f8",
   "metadata": {},
   "source": [
    "## *******************"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
